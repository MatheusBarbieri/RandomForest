{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from numpy.random import randint\n",
    "from collections import Counter\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/dataset_31_credit-g.csv', nrows=20)\n",
    "wine_df = pd.read_csv('../data/dataset_191_wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df[df['installment_commitment'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = a.groupby(df['installment_commitment'] > df['installment_commitment'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open('../data/dataset_31_credit-g.json', 'r')\n",
    "credits_kinds = json.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('../data/dataset_191_wine.json', 'r')\n",
    "wine_kinds = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_k_folds(df, k, add_remaining, seed):\n",
    "    fold_size = len(df) // k\n",
    "\n",
    "    folds = []\n",
    "    for i in range(k):\n",
    "        sample = df.sample(n=fold_size, random_state=seed)\n",
    "        df = df.drop(sample.index, errors='ignore')\n",
    "        folds.append(sample)\n",
    "\n",
    "    # add remaining elements to folds\n",
    "    if add_remaining:\n",
    "        for i in range(len(df)):\n",
    "            folds[i] = pd.concat([folds[i], df.iloc[i:i+1]])\n",
    "\n",
    "    return folds\n",
    "\n",
    "\n",
    "def _stratified_k_folds(df, k, add_remaining, seed):\n",
    "    groups = df.groupby('class')\n",
    "    folds_by_groups = [_random_k_folds(g, k, add_remaining, seed) for c, g in groups]\n",
    "    folds = [pd.concat(folds_by_groups[x][y] for x in range(len(folds_by_groups))) for y in range(k)]\n",
    "    return folds\n",
    "\n",
    "\n",
    "def generate_k_folds(df, k, sampling='stratified', add_remaining=True, seed=randint(10000)):\n",
    "    if sampling == 'random':\n",
    "        return _random_k_folds(df, k, add_remaining, seed)\n",
    "    elif sampling == 'stratified':\n",
    "        return _stratified_k_folds(df, k, add_remaining, seed)\n",
    "    else:\n",
    "        raise Exception(\"Sampling parameter must be one of [stratified, random]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bootstraps(df, n, seed=randint(10000)):\n",
    "    bootstraps = []\n",
    "    for i in range(n):\n",
    "        sample = df.sample(frac=1, replace=True, random_state=seed+i)\n",
    "        bootstraps.append(sample)\n",
    "\n",
    "    return bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_splits(folds):\n",
    "    sets = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        sets.append((pd.concat(folds[:i] + folds[i + 1:]), folds[i]))\n",
    "\n",
    "    return sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def timeit(method):\n",
    "    def func(*args, **kw):\n",
    "        start = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        end = time.time()\n",
    "\n",
    "        print(\"{}: {} seconds\".format(method.__name__, (start - end)))\n",
    "        return result\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_string(tree, depth=0):\n",
    "    DEFAULT_COLOR = '\\033[39m'\n",
    "    ATTR_COLOR = '\\033[33m'\n",
    "    NOMINAL_COLOR = '\\033[34m'\n",
    "    NUMERIC_COLOR = '\\033[31m'\n",
    "    CLASS_COLOR = '\\033[32m'\n",
    "\n",
    "    spacing = \"    \" * depth\n",
    "\n",
    "    if tree.target_class:\n",
    "        string = CLASS_COLOR + str(tree.target_class) + DEFAULT_COLOR\n",
    "        return string\n",
    "\n",
    "    if depth == 0:\n",
    "        string = ATTR_COLOR + str(tree.attribute) + DEFAULT_COLOR + \":\\n\"\n",
    "    else:\n",
    "        string = ATTR_COLOR + \"\\n\" + spacing + str(tree.attribute) + DEFAULT_COLOR + \":\\n\"\n",
    "\n",
    "    if tree.kind == \"nominal\":\n",
    "        for option in tree.options.items():\n",
    "            attr_name = NOMINAL_COLOR + str(option[0]) + DEFAULT_COLOR + \": \"\n",
    "            string = string + spacing + attr_name + tree_to_string(option[1], depth + 1) + \"\\n\"\n",
    "    else:\n",
    "        for option in tree.options.items():\n",
    "            signal = \" > \" if option[0] else \" < \"\n",
    "            attr_name = NUMERIC_COLOR + str(f\"{tree.cut:.4f}\") + DEFAULT_COLOR + signal \\\n",
    "                + NOMINAL_COLOR + tree.attribute + DEFAULT_COLOR + \": \"\n",
    "            string = string + spacing + attr_name + tree_to_string(option[1], depth + 1) + \"\\n\"\n",
    "\n",
    "    string = string[:-1]\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "def group_by_attribute(attribute, df):\n",
    "    if attribute[1] == \"nominal\":\n",
    "        return df.groupby(attribute[0])\n",
    "    else:\n",
    "        return df.groupby(df[attribute[0]] > df[attribute[0]].mean())\n",
    "\n",
    "def info(df):\n",
    "    total = len(df)\n",
    "    class_counts = df['class'].value_counts().to_list()\n",
    "    total_info = 0\n",
    "\n",
    "    for c in class_counts:\n",
    "        x = c / total\n",
    "        total_info = total_info - x * log2(x)\n",
    "\n",
    "    return total_info\n",
    "\n",
    "\n",
    "def info_attribute(attribute, df):\n",
    "    instances_by_attribute = group_by_attribute(attribute, df)\n",
    "    df_size = len(df)\n",
    "    total_info = 0\n",
    "\n",
    "    for _, group in instances_by_attribute:\n",
    "        group_size = len(group)\n",
    "        total_info = total_info + group_size / df_size * info(group)\n",
    "\n",
    "    return total_info\n",
    "\n",
    "\n",
    "def gain(attr, df):\n",
    "    return info(df) - info_attribute(attr, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import random\n",
    "\n",
    "@jit(nopython=True)\n",
    "def np_info(counts, group_size, total_size):\n",
    "    total_info = 0\n",
    "    for c in counts:\n",
    "        x = c / group_size\n",
    "        total_info = total_info - x * np.log2(x)\n",
    "        \n",
    "    return group_size / total_size * total_info\n",
    "\n",
    "def info_attributes_calc(data, attributes, column_index):\n",
    "    class_pos = column_index['class']\n",
    "    total_size = len(data)\n",
    "    \n",
    "    infos = []\n",
    "    for attr, kind in attributes:\n",
    "        if kind == \"nominal\":\n",
    "            unique = np.unique(data[:, column_index[attr]])\n",
    "            groups = [data[data[:, column_index[attr]] == u] for u in unique]\n",
    "        else:\n",
    "            mean = data[:, column_index[attr]].mean()\n",
    "            groups = [data[data[:, column_index[attr]] <= mean], data[data[:, column_index[attr]] > mean]]\n",
    "            \n",
    "        attr_info = 0\n",
    "        for group in groups:\n",
    "            group_size = len(group)\n",
    "            class_column = group[:, class_pos]\n",
    "            classes, counts = np.unique(class_column, return_counts=True)\n",
    "            \n",
    "            attr_info = attr_info + np_info(counts, group_size, total_size)\n",
    "        \n",
    "        infos.append(attr_info)\n",
    "    return infos\n",
    "\n",
    "def info_attributes(df, attributes):\n",
    "    column_index = {v: i for i, v in enumerate(df.columns.values)}\n",
    "    data = df.values\n",
    "    return info_attributes_calc(data, attributes, column_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661 µs ± 43.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test_attributes = take_m(test_kinds, 3)\n",
    "info_attributes(test_df, test_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628 µs ± 16.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test_attributes = take_m(test_kinds, 3)\n",
    "info_attributes(test_df, test_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.1 ms ± 3.88 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "info_attribute((\"age\", \"nominal\"), test_df)\n",
    "info_attribute((\"income\", \"numerical\"), test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _most_frequent_class(df):\n",
    "    return df['class'].value_counts().idxmax()\n",
    "\n",
    "def take_m(attributes, m):\n",
    "    attribute_list = list(attributes.items())\n",
    "    if m and len(attribute_list) >= m:\n",
    "        attribute_list = random.sample(attribute_list, m)\n",
    "    return attribute_list\n",
    "    \n",
    "def _choose_best_attribute(attributes, df, m):\n",
    "    attribute_list = take_m(attributes, m)\n",
    "    results = info_attributes(df, attribute_list)\n",
    "    choice = attribute_list[results.index(min(results))]\n",
    "    return choice\n",
    "\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self, options=None, target_class=None, attribute=None, kind=None, cut=None):\n",
    "        self.target_class = target_class\n",
    "        self.options = options\n",
    "        self.attribute = attribute\n",
    "        self.kind = kind\n",
    "        self.cut = cut\n",
    "\n",
    "    def __str__(self):\n",
    "        return tree_to_string(self)\n",
    "\n",
    "    @classmethod\n",
    "    def generate(cls, df, attributes, m=None):\n",
    "        if df['class'].nunique() == 1:\n",
    "            return Tree(target_class=df['class'].iloc[0])\n",
    "\n",
    "        elif not attributes:\n",
    "            return Tree(target_class=_most_frequent_class(df))\n",
    "\n",
    "        else:\n",
    "            best_attribute = _choose_best_attribute(attributes, df, m)\n",
    "            name, kind = best_attribute\n",
    "\n",
    "            groups = group_by_attribute(best_attribute, df)\n",
    "            new_attributes = {k: v for k, v in attributes.items() if k != name}\n",
    "\n",
    "            def gen_options():\n",
    "                return {c: cls.generate(group, new_attributes, m) for c, group in groups}\n",
    "\n",
    "            cut = df[name].mean() if kind == \"numeric\" else None\n",
    "\n",
    "            return Tree(\n",
    "                attribute=name,\n",
    "                kind=kind,\n",
    "                options=gen_options(),\n",
    "                cut=cut\n",
    "            )\n",
    "\n",
    "\n",
    "def predict(tree, instance):\n",
    "    if tree.target_class:\n",
    "        return tree.target_class\n",
    "\n",
    "    try:\n",
    "        if tree.kind == \"nominal\":\n",
    "            sub_tree = tree.options[instance[tree.attribute]]\n",
    "        else:\n",
    "            sub_tree = tree.options[instance[tree.attribute] > tree.cut]\n",
    "    except KeyError:\n",
    "        print(\"Instance attribute has no class in tree node, using first option available\")\n",
    "        sub_tree = next(iter(tree.options.values()))\n",
    "\n",
    "    return predict(sub_tree, instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_predict = predict\n",
    "\n",
    "class Forest:\n",
    "    def __init__(self, trees):\n",
    "        self.trees = trees\n",
    "\n",
    "    @classmethod\n",
    "    def generate(cls, train_set, attributes, ntree, m=None, pool=None):\n",
    "        bootstraps = generate_bootstraps(train_set, ntree)\n",
    "        wraped_bootstraps = [(b, attributes, m) for b in bootstraps]\n",
    "        if pool:\n",
    "            trees = pool.starmap(Tree.generate, wraped_bootstraps)\n",
    "        else:\n",
    "            trees = [Tree.generate(b, attributes, m) for b in bootstraps]\n",
    "\n",
    "        return Forest(trees)\n",
    "\n",
    "    def predict(self, instance, pool=None):\n",
    "        wraped_trees = [(tree, instance) for tree in self.trees]\n",
    "        if pool:\n",
    "            results = pool.starmap(tree_predict, wraped_trees)\n",
    "        else:\n",
    "            results = [tree_predict(tree, instance) for tree in self.trees]\n",
    "\n",
    "        data = Counter(results)\n",
    "        result = max(results, key=data.get)\n",
    "        return result\n",
    "\n",
    "    def predict_df(self, instances):\n",
    "        instances['predicted'] = instances.apply(lambda x: self.predict(x), axis=1)\n",
    "        return instances[['class', 'predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = generate_k_folds(wine_df, 10)\n",
    "splits = generate_splits(k_folds)\n",
    "train, test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_forest = Forest.generate(train, wine_kinds, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 18, classified correctly: 18\n",
      "Total: 18, classified correctly: 18\n"
     ]
    }
   ],
   "source": [
    "results = wine_forest.predict_df(splits[7][1])\n",
    "results2 = wine_forest.predict_df(splits[2][1])\n",
    "print(\"Total: {}, classified correctly: {}\".format(len(results), len(results[results['predicted'] == results['class']])))\n",
    "print(\"Total: {}, classified correctly: {}\".format(len(results2), len(results2[results2['predicted'] == results2['class']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, counts = np.unique(np.array(['c', 'a', 'b', 'b', 'c', 'c']), return_counts=True)\n",
    "values[counts.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000 [Total: 18, Correct: 18]\n",
      "Macro Recall: 1.000\n",
      "  Recall for class 1: 1.000\n",
      "  Recall for class 2: 1.000\n",
      "  Recall for class 3: 1.000\n",
      "Macro Precision: 1.000\n",
      "  Precision for class 1: 1.000\n",
      "  Precision for class 2: 1.000\n",
      "  Precision for class 3: 1.000\n",
      "Macro Specificity: 1.000\n",
      "  Specificity for class 1: 1.000\n",
      "  Specificity for class 2: 1.000\n",
      "  Specificity for class 3: 1.000\n",
      "Macro F-measure (ß = 0.5): 1.000\n",
      "  F-measure (ß = 0.5) for class 1: 1.000\n",
      "  F-measure (ß = 0.5) for class 2: 1.000\n",
      "  F-measure (ß = 0.5) for class 3: 1.000\n",
      "Macro F-measure (ß = 1): 1.000\n",
      "  F-measure (ß = 1) for class 1: 1.000\n",
      "  F-measure (ß = 1) for class 2: 1.000\n",
      "  F-measure (ß = 1) for class 3: 1.000\n",
      "Macro F-measure (ß = 2): 1.000\n",
      "  F-measure (ß = 2) for class 1: 1.000\n",
      "  F-measure (ß = 2) for class 2: 1.000\n",
      "  F-measure (ß = 2) for class 3: 1.000\n"
     ]
    }
   ],
   "source": [
    "class ConfusionMatrix:\n",
    "    def __init__(self, results):\n",
    "        self._results = results\n",
    "        self._total = len(results)\n",
    "        self._correct = len(results[results['predicted'] == results['class']])\n",
    "        self._cm = pd.crosstab(results['class'], results['predicted'], rownames=['actual'])\n",
    "\n",
    "    def __add__(self, val):\n",
    "        new_results = pd.concat([self._results, val.results])\n",
    "        return ConfusionMatrix(new_results)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._cm.__repr__()\n",
    "\n",
    "    def print(self):\n",
    "        print(self._cm)\n",
    "\n",
    "    def true_positives(self):\n",
    "        tps = pd.Series(np.diag(self._cm), index=self._cm.index)\n",
    "        return tps.rename_axis('TruePositives')\n",
    "\n",
    "    def true_negatives(self):\n",
    "        tns = [self._cm.drop(index=[c], columns=[c]).values.sum() for c in self._cm.index]\n",
    "        return pd.Series(tns, index=self._cm.index).rename_axis('TrueNegatives')\n",
    "\n",
    "    def false_positives(self):\n",
    "        fps = [self._cm.loc[c].sum() - self._cm[c][c] for c in self._cm.index]\n",
    "        return pd.Series(fps, index=self._cm.index).rename_axis('FalsePositives')\n",
    "\n",
    "    def false_negatives(self):\n",
    "        fns = [self._cm[c].sum() - self._cm[c][c] for c in self._cm.index]\n",
    "        return pd.Series(fns, index=self._cm.index).rename_axis('FalseNegatives')\n",
    "\n",
    "    def accuracy(self):\n",
    "        return self._correct / self._total\n",
    "\n",
    "    def error(self):\n",
    "        return 1 - self.accuracy()\n",
    "\n",
    "    def recalls(self):\n",
    "        tps = self.true_positives()\n",
    "        fns = self.false_negatives()\n",
    "        recalls = tps / (tps + fns)\n",
    "        return recalls.rename_axis('Recall')\n",
    "\n",
    "    def precisions(self):\n",
    "        tps = self.true_positives()\n",
    "        fps = self.false_positives()\n",
    "        precisions = tps / (tps + fps)\n",
    "        return precisions.rename_axis('Precision')\n",
    "\n",
    "    def specificities(self):\n",
    "        tns = self.true_negatives()\n",
    "        fps = self.false_positives()\n",
    "        specificities = tns / (tns + fps)\n",
    "        return specificities.rename_axis('Specificity')\n",
    "\n",
    "    def f_measures(self, b):\n",
    "        prec = self.precisions()\n",
    "        rec = self.recalls()\n",
    "        f_measures = ((1 + b**2) * prec * rec / (b**2 * prec + rec))\n",
    "        return f_measures.rename_axis('F-measure')\n",
    "\n",
    "    def macro_recall(self):\n",
    "        return self.recalls().mean()\n",
    "\n",
    "    def macro_precision(self):\n",
    "        return self.precisions().mean()\n",
    "\n",
    "    def macro_specificity(self):\n",
    "        return self.specificities().mean()\n",
    "\n",
    "    def macro_f_measure(self, b):\n",
    "        return self.f_measures(b).mean()\n",
    "\n",
    "    def micro_recall(self):\n",
    "        tps = self.true_positives().sum()\n",
    "        fns = self.false_negatives().sum()\n",
    "        recall = tps / (tps + fns)\n",
    "        return recall\n",
    "\n",
    "    def micro_precision(self):\n",
    "        tps = self.true_positives().sum()\n",
    "        fps = self.false_positives().sum()\n",
    "        precision = tps / (tps + fps)\n",
    "        return precision\n",
    "\n",
    "    def micro_f_measure(self, b):\n",
    "        prec = self.precisions().sum()\n",
    "        rec = self.recalls().sum()\n",
    "        f_measure = ((1 + b**2) * prec * rec / (b**2 * prec + rec))\n",
    "        return f_measure\n",
    "\n",
    "    def show(self, verbose=False):\n",
    "        print(f\"Accuracy: {self.accuracy():.3f} [Total: {self._total}, Correct: {self._correct}]\")\n",
    "        print(f\"Macro Recall: {self.macro_recall():.3f}\")\n",
    "        if verbose:\n",
    "            for k, v in self.recalls().items():\n",
    "                print(f\"  Recall for class {k}: {v:.3f}\")\n",
    "        print(f\"Macro Precision: {self.macro_precision():.3f}\")\n",
    "        if verbose:\n",
    "            for k, v in self.precisions().items():\n",
    "                print(f\"  Precision for class {k}: {v:.3f}\")\n",
    "        print(f\"Macro Specificity: {self.macro_specificity():.3f}\")\n",
    "        if verbose:\n",
    "            for k, v in self.specificities().items():\n",
    "                print(f\"  Specificity for class {k}: {v:.3f}\")\n",
    "        for b in [0.5, 1, 2]:\n",
    "            print(f\"Macro F-measure (ß = {b}): {self.macro_f_measure(b):.3f}\")\n",
    "            if verbose:\n",
    "                for k, v in self.f_measures(b).items():\n",
    "                    print(f\"  F-measure (ß = {b}) for class {k}: {v:.3f}\")\n",
    "            \n",
    "cm = ConfusionMatrix(results)\n",
    "cm.show(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1 2 3]'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(np.unique(cm._results.values[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1.0, 1.0, 1.0]'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(cm.recalls().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree = Tree.generate(test_df, test_kinds)\n",
    "wine_tree = Tree.generate(wine_df, wine_kinds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_class': None,\n",
       " 'options': {False: <__main__.Tree at 0x10d655e10>,\n",
       "  True: <__main__.Tree at 0x10d5b7550>},\n",
       " 'attribute': 'income',\n",
       " 'kind': 'numeric',\n",
       " 'cut': 6370.0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(test_tree.options['senior'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mFlavanoids\u001b[39m:\n",
      "\u001b[31m2.0293\u001b[39m < \u001b[34mFlavanoids\u001b[39m: \u001b[33m\n",
      "    Hue\u001b[39m:\n",
      "    \u001b[31m0.8378\u001b[39m < \u001b[34mHue\u001b[39m: \u001b[33m\n",
      "        Color_intensity\u001b[39m:\n",
      "        \u001b[31m7.3911\u001b[39m < \u001b[34mColor_intensity\u001b[39m: \u001b[33m\n",
      "            OD280%2FOD315_of_diluted_wines\u001b[39m:\n",
      "            \u001b[31m1.6965\u001b[39m < \u001b[34mOD280%2FOD315_of_diluted_wines\u001b[39m: \u001b[32m3\u001b[39m\n",
      "            \u001b[31m1.6965\u001b[39m > \u001b[34mOD280%2FOD315_of_diluted_wines\u001b[39m: \u001b[33m\n",
      "                Alcohol\u001b[39m:\n",
      "                \u001b[31m12.9350\u001b[39m < \u001b[34mAlcohol\u001b[39m: \u001b[33m\n",
      "                    Malic_acid\u001b[39m:\n",
      "                    \u001b[31m3.3925\u001b[39m < \u001b[34mMalic_acid\u001b[39m: \u001b[32m3\u001b[39m\n",
      "                    \u001b[31m3.3925\u001b[39m > \u001b[34mMalic_acid\u001b[39m: \u001b[32m2\u001b[39m\n",
      "                \u001b[31m12.9350\u001b[39m > \u001b[34mAlcohol\u001b[39m: \u001b[32m3\u001b[39m\n",
      "        \u001b[31m7.3911\u001b[39m > \u001b[34mColor_intensity\u001b[39m: \u001b[32m3\u001b[39m\n",
      "    \u001b[31m0.8378\u001b[39m > \u001b[34mHue\u001b[39m: \u001b[33m\n",
      "        Malic_acid\u001b[39m:\n",
      "        \u001b[31m1.9500\u001b[39m < \u001b[34mMalic_acid\u001b[39m: \u001b[32m2\u001b[39m\n",
      "        \u001b[31m1.9500\u001b[39m > \u001b[34mMalic_acid\u001b[39m: \u001b[33m\n",
      "            Alcohol\u001b[39m:\n",
      "            \u001b[31m12.7275\u001b[39m < \u001b[34mAlcohol\u001b[39m: \u001b[32m2\u001b[39m\n",
      "            \u001b[31m12.7275\u001b[39m > \u001b[34mAlcohol\u001b[39m: \u001b[33m\n",
      "                Ash\u001b[39m:\n",
      "                \u001b[31m2.5314\u001b[39m < \u001b[34mAsh\u001b[39m: \u001b[33m\n",
      "                    Alcalinity_of_ash\u001b[39m:\n",
      "                    \u001b[31m21.2500\u001b[39m < \u001b[34mAlcalinity_of_ash\u001b[39m: \u001b[32m3\u001b[39m\n",
      "                    \u001b[31m21.2500\u001b[39m > \u001b[34mAlcalinity_of_ash\u001b[39m: \u001b[32m2\u001b[39m\n",
      "                \u001b[31m2.5314\u001b[39m > \u001b[34mAsh\u001b[39m: \u001b[32m3\u001b[39m\n",
      "\u001b[31m2.0293\u001b[39m > \u001b[34mFlavanoids\u001b[39m: \u001b[33m\n",
      "    Alcohol\u001b[39m:\n",
      "    \u001b[31m13.1667\u001b[39m < \u001b[34mAlcohol\u001b[39m: \u001b[33m\n",
      "        Color_intensity\u001b[39m:\n",
      "        \u001b[31m3.4561\u001b[39m < \u001b[34mColor_intensity\u001b[39m: \u001b[32m2\u001b[39m\n",
      "        \u001b[31m3.4561\u001b[39m > \u001b[34mColor_intensity\u001b[39m: \u001b[33m\n",
      "            Proline\u001b[39m:\n",
      "            \u001b[31m750.0000\u001b[39m < \u001b[34mProline\u001b[39m: \u001b[32m2\u001b[39m\n",
      "            \u001b[31m750.0000\u001b[39m > \u001b[34mProline\u001b[39m: \u001b[32m1\u001b[39m\n",
      "    \u001b[31m13.1667\u001b[39m > \u001b[34mAlcohol\u001b[39m: \u001b[33m\n",
      "        Ash\u001b[39m:\n",
      "        \u001b[31m2.4558\u001b[39m < \u001b[34mAsh\u001b[39m: \u001b[32m1\u001b[39m\n",
      "        \u001b[31m2.4558\u001b[39m > \u001b[34mAsh\u001b[39m: \u001b[33m\n",
      "            Alcalinity_of_ash\u001b[39m:\n",
      "            \u001b[31m18.1652\u001b[39m < \u001b[34mAlcalinity_of_ash\u001b[39m: \u001b[32m1\u001b[39m\n",
      "            \u001b[31m18.1652\u001b[39m > \u001b[34mAlcalinity_of_ash\u001b[39m: \u001b[33m\n",
      "                Proanthocyanins\u001b[39m:\n",
      "                \u001b[31m1.8520\u001b[39m < \u001b[34mProanthocyanins\u001b[39m: \u001b[32m1\u001b[39m\n",
      "                \u001b[31m1.8520\u001b[39m > \u001b[34mProanthocyanins\u001b[39m: \u001b[33m\n",
      "                    Color_intensity\u001b[39m:\n",
      "                    \u001b[31m5.3825\u001b[39m < \u001b[34mColor_intensity\u001b[39m: \u001b[32m2\u001b[39m\n",
      "                    \u001b[31m5.3825\u001b[39m > \u001b[34mColor_intensity\u001b[39m: \u001b[32m1\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "print(wine_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
